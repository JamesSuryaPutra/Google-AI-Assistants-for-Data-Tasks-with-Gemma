# Google - AI Assistants for Data Tasks with Gemma
<img width="560" height="280" alt="image" src="https://github.com/user-attachments/assets/daa85903-940e-440c-a365-719407212ce9" />


# Overview
Google recently launched Gemma, a new family of open LLMs built from the same research and technology used to create their Gemini models. In this competition, you’re challenged to demonstrate how to use Gemma to accomplish one or more data science oriented tasks.

# Description
Large Language Models (LLMs) have captured the world's attention and imagination.

Often referred to as "foundation models", much of their potential lies in their ability to be adapted to accomplish specialized tasks for a seemingly unlimited number of use cases. As the technology rapidly develops, there’s a massive opportunity to uncover the best methods and approaches for adapting LLMs to new and specialized use cases.

The goal of this competition is to create a notebook that demonstrates how to use the Gemma LLM to accomplish one of the following data science oriented tasks:
- Explain or teach basic data science concepts.
- Answer common questions about the Python programming language.
- Summarize Kaggle solution write-ups.
- Explain or teach concepts from Kaggle competition solution write-ups.
- Answer common questions about the Kaggle platform.

By participating in this competition, you'll both be building a useful tool and contributing to the ML field's collective knowledge of how to best sharpen LLMs for real-world needs.

# Evaluation
- Eligibility Criteria
  - Compliant: The submission was consistent with the guidelines and instructions.
  - Topical: The submission was relevant to one of the 5x topics.
  - Open: The notebook and all of the underlying data sources were made public.
- Evaluation Rubric
  - Technical: The approach made efficient use of strategies such as few-shot prompting, retrieval-augmented generation, and/or fine-tuning.
  - Descriptive: The code was well-documented, with markdown cells that both explained the code and provided context.
  - Useful: The approach produces outputs that are helpful or high quality.
  - Robust: The approach works well when tested with additional inputs.
